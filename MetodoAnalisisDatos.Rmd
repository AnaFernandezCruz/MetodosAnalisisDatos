---
title: "Métodos de Análisis de Datos"
author: "Ana Fernández Cruz, Jesús Gallego Olivas y Miguel Ángel Sánchez Alcázar."
output: html_document
---

A continuación, se detallan los diferentes apartados evaluables en el desarrollo de la práctica y su puntuación. La puntuación completa corresponde al correcto uso, y justificación, de cada una de las técnicas empleadas.

1. Uso de herramienta/s de control de versiones (1 punto)

Para el control de versiones utilizaremos github. El repositorio se encuentra en https://github.com/AnaFernandezCruz/MetodosAnalisisDatos

2. Definición de objetivos (1 punto)

La presente práctica intentará crear un modelo de regresión lineal múltiple para un dataset con las siguientes características. La variable que se intentará inferir será la esperanza de vida


3. Análisis exploratorio inicial (1 punto)

Antes de empezar a realizar la práctica tenemos que cargar los dataset incluidos en la página de Kaggle, unificarlos en un solo dataset y dividirlo en train/test/validación. Para ello:

```{r message=FALSE, warning=FALSE}
library(readr)
library(dplyr)

pathDatos = './Dataset/'
pathLocal = './'
fileTrain = paste(pathDatos,"train.csv",sep="", collapse = NULL)
fileTest = paste(pathDatos,"test.csv",sep="", collapse = NULL)
fileDatosPK = paste(pathDatos,"sample_submission.csv",sep="", collapse = NULL)
fileDatosTrainTest = paste(pathLocal,"train_test.csv",sep="", collapse = NULL)
fileDatosValidacion = paste(pathLocal,"validacion.csv",sep="", collapse = NULL)

borra_columnas_muchos_faltantes = FALSE
borra_columnas_incomodas = FALSE
columnas_borrar_faltantes <- c('FireplaceQu','Fence','Alley','MiscFeature','PoolQC','GarageType','GarageCond','GarageQual','GarageFinish','GarageYrBit','LoftFrontage')
columnas_borrar_incomodas <- c('BsmtFinType1','LowQualFinSF','MasVnrArea','BsmtHalfBath','EnclosedPorch','KitchenAbvGr','MiscVal','PoolArea','ScreenPorch','Utilities','Condition2','RoofMalt','Heating','Street')

    train_kaggle <- read_csv(fileTrain)
    head(train_kaggle)
    
    test_kaggle <- read_csv(fileTest)
    head(test_kaggle)
    
    claves_primarias <- read_csv(fileDatosPK)
    head(claves_primarias)
    
    #Mergeamos el archivo de train y test ya que tienen las mismas columnas.
    
    #test_kaggle <- dplyr::inner_join(x=test_kaggle,y=claves_primarias,by = c('Id','Id'))   
    #full_dataset <- dplyr::union(train_kaggle, test_kaggle)
    #full_dataset_completo <- dplyr::union(train_kaggle, test_kaggle)
    #head(full_dataset)
    
    
    
    ## Completamos test con la columna que falta
    total_test <- merge(test_kaggle,claves_primarias,by="Id")
    
    # Unimos train y test completo
    full_dataset <- rbind(train_kaggle,total_test)
    
    ## Desordenamos todo el dataset
    set.seed(42)
    rows <- sample(nrow(full_dataset))
    full_dataset <- full_dataset[rows, ]

    
    ## Conseguimos el 10% para validacion
    split_validacion <-sort(sample(nrow(full_dataset), nrow(full_dataset)*.1))

    

    if(borra_columnas_muchos_faltantes) {
    
      #full_dataset = subset( full_dataset, select = -columnas_borrar_faltantes)
      full_dataset <- full_dataset %>% dplyr::select(-one_of(columnas_borrar_faltantes))
    
    }
  
    if(borra_columnas_incomodas) {
      #full_dataset = subset( full_dataset, select = -columnas_borrar_faltantes)
      full_dataset <- full_dataset %>% select(-one_of(columnas_borrar_incomodas))
    }
    
    validacion <-full_dataset[split_validacion, ]
    if(!file.exists(fileDatosTrainTest)) {
      write.csv(validacion, fileDatosValidacion,row.names=F)
    }
    
    train_test<-full_dataset[-split_validacion,]
    if(!file.exists(fileDatosTrainTest)) {
      write.csv(train_test, fileDatosTrainTest,row.names=F)
    }
  


train_test <- read_csv(fileDatosTrainTest)
set.seed(55)
dt = sort(sample(nrow(train_test), nrow(train_test)*.7))
train<-train_test[dt,]
test<-train_test[-dt,]

```

Una vez realizado el proceso de separación del dataset completo en tres partes (test, train y validación final) realizaremos un primer resumen del estdo del dataset:


```{r message=FALSE, warning=FALSE}
library(DataExplorer)
introduce(train_test)
```

   Vemos que el dataset está dividio en:
    * 81 variables distintas, en las que una de ellas es la clave principal (denominada Id) que no debermos tener en cuenta en el análisis de regresión. De estas variables, 43 son discretas y 38 contínuas. Vemos también que hay una gran cantidad de "missings" y el valor de "complete_row" es cero, lo que indica que ha habido algún problema con la lectura del dataset en algunas columnas.

  Realizaremos un gráfico mirando la distribución de los datos por tipos y otra información que la anterior tabla ya incluía:

```{r message=FALSE, warning=FALSE}
plot_intro(train_test)
```

 Como hemos indicado antes, vemos que este gráfico muestra en los valores de "complete rows" un valor del 0%, lo cuál parece indicar un problema con alguna columna en particular.  Lo que observamos es que el valor NA es un valor de algunas de las columnas válido, con lo que habría que corregir esto para estas columnas y volver a hacer el análisis. Supondremos que para estas columnas no existe ningún valor genuinamente en blanco:

   Alley: NA 	No alley access
   BsmtQual: NA	No Basement
   BsmtCond: NA	No Basement
   BsmtExposure: NA	No Basement
   BsmtFinType1: NA	No Basement
   BsmtFinType2:  NA	No Basement
   GarageType: NA	No Garage
   GarageFinish: NA	No Garage
   GarageQual: : NA	No Garage
   GarageCond: : NA	No Garage
   PoolQC:  NA	No Pool
   Fence:  NA	No Fence
   MiscFeature:   NA	None
 
 El siguiente código realiza la transformación anterior:
   
```{r message=FALSE, warning=FALSE}

  columnas_sustitucion_nas <- c('Alley','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','GarageType','GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature','FireplaceQu')



full_dataset <- mutate_at(full_dataset, columnas_sustitucion_nas, 
          list(~ifelse(is.na(.), 'NA',.)) )


train_test <- mutate_at(train_test, columnas_sustitucion_nas, 
          list(~ifelse(is.na(.), 'NA',.)) )

train <- mutate_at(train, columnas_sustitucion_nas, 
          list(~ifelse(is.na(.), 'NA',.)) )


test <- mutate_at(test, columnas_sustitucion_nas, 
          list(~ifelse(is.na(.), 'NA',.)) )


```
   

 Las variables que nos encontraremos en el dataset son las siguientes:
  * MSSubClass: la clase de construcción
  * MSZoning: la clasificación general de zonificación
  * LotFrontage: pies lineales de calle conectados a la propiedad
  * LotArea: tamaño del lote en pies cuadrados
  * Street:  tipo de acceso por carretera
  * Alley: tipo de acceso al callejón
  * LotShape: forma general de propiedad
  * LandContour: llanura de la propiedad
  * Utilities:  tipo de utilidades disponibles
  * LotConfig: configuración del lote
  * LandSlope: pendiente de la propiedad
  * Neighborhood: ubicaciones físicas dentro de los límites de la ciudad de Ames
  * Condition1:  Proximidad a la carretera principal o ferrocarril
  * Condition2:  Proximidad a la carretera principal o al ferrocarril (si hay un segundo)
  * BldgType: tipo de vivienda
  * HouseStyle: estilo de vivienda
  * OverallQual: material general y calidad de acabado
  * OverallCond: calificación de condición general
  * YearBuilt: fecha de construcción original
  * YearRemodAdd: fecha de remodelación
  * RoofStyle: tipo de techo
  * RoofMatl: material del techo
  * Exterior1st: cubierta exterior en la casa
  * Exterior2nd: revestimiento exterior de la casa (si hay más de un material)
  * MasVnrType: tipo de chapa de albañilería
  * MasVnrArea: área de revestimiento de mampostería en pies cuadrados
  * ExterQual: calidad del material exterior
  * ExterCond: Condición actual del material en el exterior.
  * Foundation: : tipo de cimiento
  * BsmtQual: altura del sótano
  * BsmtCond: estado general del sótano
  * BsmtExposure: paredes de sótano a nivel de jardín o de salida
  * BsmtFinType1: Calidad del área terminada del sótano
  * BsmtFinSF1: Tipo 1 terminado pies cuadrados
  * BsmtFinType2: Calidad de la segunda área terminada (si está presente)
  * BsmtFinSF2: pies cuadrados terminados tipo 2
  * BsmtUnfSF: pies cuadrados inacabados de área de sótano
  * TotalBsmtSF: pies cuadrados totales del área del sótano
  * Heating:  tipo de calefacción
  * HeatingQC: calidad y condición de calefacción
  * CentralAir: aire acondicionado central
  * Electrical: sistema eléctrico
  * 1stFlrSF: pies cuadrados del primer piso
  * 2ndFlrSF: pies cuadrados del segundo piso
  * LowQualFinSF: pies cuadrados terminados de baja calidad (todos los pisos)
  * GrLivArea: superficie habitable por encima del nivel del suelo (pies cuadrados)
  * BsmtFullBath: baños completos en el sótano
  * BsmtHalfBath: medio baño en el sótano
  * FullBath: baños completos por encima del grado
  * HalfBath: medio baño por encima del grado
  * Bedroom: número de dormitorios por encima del nivel del sótano
  * Kitchen número de cocinas
  * KitchenQual: calidad de cocina
  * TotRmsAbvGrd: total de habitaciones por encima del grado (no incluye baños)
  * Functional: calificación de funcionalidad doméstica 
  * Fireplaces: : número de chimeneas
  * FireplaceQu: calidad de chimenea
  * GarageType: ubicación del garaje
  * GarageYrBlt: año en que se construyó el garaje
  * GarageFinish: acabado interior del garaje
  * GarageCars: tamaño del garaje en la capacidad del automóvil
  * GarageArea: tamaño del garaje en pies cuadrados
  * GarageQual: calidad de garaje
  * GarageCond: condición del garaje
  * PavedDrive: entrada pavimentada
  * WoodDeckSF: área de cubierta de madera en pies cuadrados
  * OpenPorchSF: área de porche abierto en pies cuadrados
  * Porche cerrado: área de porche cerrado en pies cuadrados
  * EnclosedPorch:  área de porche de tres estaciones en pies cuadrados
  * ScreenPorch: área del porche de la pantalla en pies cuadrados
  * PoolArea: área de la piscina en pies cuadrados
  * PoolQC: calidad de la piscina
  * Fence: calidad de la cerca
  * MiscFeature: características varias no cubiertas en otras categorías
  * MiscVal: $ Valor de la característica miscelánea
  * MoSold: Mes vendido
  * YrSold: año vendido
  * SaleType: tipo de venta
  * SaleCondition: condición de venta

 A continuación, dividiremos las variables en las siguientes categorías:
   * Variables con dominio contínuo y numérico
   * Variable con dominio numérico discreto
   * Variables descriptivas nominales  (variables que toman valores alfanumérido de un conjunto finito de valores)
   * Variables descriptivas ordinales (variables que contienen una relación de orden)
  
  El siguiente código realiza la descomposición en dichas categorías para usar con posterioridad:

```{r}

var_discretas <- c('BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars','GarageYrBlt','YearBuilt','YearRemodAdd','YrSold','MoSold')

var_continuas <- c('LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch', '3SsnPorch','ScreenPorch','PoolArea','MiscVal','SalePrice')

var_ordinales <- c('LotShape','Utilities','LandSlope','OverallQual','OverallCond','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC','CentralAir','Electrical','KitchenQual','Functional','FireplaceQu','GarageFinish','GarageQual','GarageCond','PavedDrive','PoolQC','Fence')

var_nominales <- c('MSSubClass','MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st',
'Exterior2nd','MasVnrType','Foundation','Heating','GarageType','MiscFeature', 'SaleType','SaleCondition')

var_continuas_discretas = c(var_continuas,var_discretas)

var_modelo = c()
var_columnas_eliminadas = c()
var_transformacion_log = c()
var_eliminar_correlacion = c()
var_creadas_transformacion = c()


```


  A continuación realizaremos un pequeño informe mostrando algunas características de los datos que contienen el dataset:

```{r message=FALSE, warning=FALSE}
library(skimr)
library(pander)

variablesReporte <- list(
  min = min,
  max = max,
  mean = mean
)
#skim_with(numeric = variablesReporte, append = FALSE) 
skim(full_dataset)  %>% pander()

```

  Ahora nos centraremos en encontrar cuál es la distribución de missings en el dataset. Para ello, utilizaremos los siguientes gráficos:

```{r message=FALSE, warning=FALSE}
library(VIM)
aggr(train_test)
```

  Dibujaremos un histograma con la proporción de missings para las variables continuas:

```{r}
library(ggplot2)

missing_data_continuas <- train_test %>%  dplyr::select(var_continuas)  %>% plot_missing(theme_config = list(legend.position = "bottom", axis.text.x =element_text(angle = 90),axis.text.y = element_text(size = rel(1))))

```

  Observamos que solo úna de las variables tiene una cantidad moderada de datos faltantes ("LotFrontage").

  Ahora repetiremos este procedimiento para las variables discretas:

```{r}

missing_data_discretas <- train_test %>%  dplyr::select(var_discretas)  %>% plot_missing(theme_config = list(legend.position = "bottom", axis.text.x =element_text(angle = 90),axis.text.y = element_text(size = rel(1))))

```

  En este caso la variable "GarageYrBlt" tiene la mayor cantidad de valores faltantes.

  Repetiremos el mismo proceso para las variables discretas ordinales:

```{r}

missing_data_ordinales <- train_test %>%  dplyr::select(var_ordinales)  %>% plot_missing(theme_config = list(legend.position = "bottom", axis.text.x =element_text(angle = 90),axis.text.y = element_text(size = rel(1))))

```

  Y por último las nominales:

```{r}

missing_data_nominales <- train_test %>%  dplyr::select(var_nominales)  %>% plot_missing(theme_config = list(legend.position = "bottom", axis.text.x =element_text(angle = 90),axis.text.y = element_text(size = rel(1))))

```

  En ninguno de los casos  se observan grandes proporciones de datos faltantes.
  
  Ahora comenzaremos con el análisis univariante de los datos del dataset.  Empezaremos dicho análisis mostrando un conjunto de histogramas para las variables nominales:


```{r}
train_test %>%  dplyr::select(var_nominales)  %>% plot_bar()
```

  A la vista de estos diagramas, observamos lo siguiente:
      * Existe una gran cantidad de variables que tienen una varianza muy reducida, tales como Street, Alley, LandContour, Condition1, Condition2, RoofStyle, RoofMtl, Heating, GarageType, SaleCondition. Estas variables pueden ser problemáticas al realizar el proceso de regresión lineal para el que este tipo de varialbes puede ser problemático, por no contar que para estos modelos este tipo de variables tienen muy poco poder predictivo.
    
    El siguiente código detectara las variables que tienen baja varianza e intentara eliminar todas aquellas que no sean significativas en una regresión de ella con la variable salePrice :

```{r}
library(caret)
elementosBajaVarianza <- nearZeroVar(train_test,freqCut = 95/5,uniqueCut = 10)

# funcion para eliminar elementos con baja correlacion
lmp <- function (modelobject) {
    if (class(modelobject) != "lm") stop("No es un objeto de tipo regresion lineal 'lm' ")
    f <- summary(modelobject)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    return(p)
}

# estas columna dan problemas
var_columnas_eliminadas = c(var_columnas_eliminadas,'3SsnPorch')

for(i in colnames(train_test)[elementosBajaVarianza]) {
  if(i != '3SsnPorch') {
    modelRegression <- lm(reformulate(termlabels = i, response = 'SalePrice') ,data=train_test)
    if(lmp(modelRegression) >.05) {
      var_eliminar_correlacion = c(var_eliminar_correlacion,i)
    }
  }
}

(var_eliminar_correlacion)

```

    Otra cosa que se observa en los anteriores diagramas es que todas las distribuciones continen un alto grado de asimetría (Skewness), cosa que habrá que tener en cuenta por si hay que realizar algún tipo de transformación sobre ellas en futuros apartados de la práctica:
    
      Ahora realizaremos el mismo análisis con las variables ordinales:

```{r}
train_test %>%  dplyr::select(var_ordinales)  %>% plot_bar()
```

   Se observan práctimante las mismas anomalías en en el caso anterior.

   Proseguiremos con las variables contínuas:
  
```{r}
train_test %>%  dplyr::select(var_continuas) %>% plot_histogram()
```

    Los comentarios que se pueden hacer en este caso son los siguientes:
      * Muy pocas variables parecen seguir una distribución normal y casi todas tienen un fuerte sesgo hacia la izquierda (y unas pocas a la derecha), sugeriendo para muchas de ellas una transformación de tipo logarítmico. Además, algunas de ellas parecen presentar numerosos "outliers" debido a que el rango de variación de las mismas es muy elevado en una gran parte de los valores finales sin que aparezcan casi valores en los mismos. 
      * La variable "Id" es una especie de clave primária organizadora de las filas y hay que eliminarla en los procesos de regresión.

   Ahora realizaremos los mismos gráficos para las variables discretas:

```{r}
train_test %>%  dplyr::select(var_discretas) %>% plot_histogram()
```
 
     Comentarios parecidos a el análisis de distribución de las variables contínuas se pueden hacer para estas variables.

    Ahora nos ocuparemos del análisis de la variable que representa la variable dependiente en nuestro modelo, el precio de las casas. En primer lugar dibujaremos su histograma:


```{r}

ggplot(train_test, aes(x=SalePrice)) + 
    geom_histogram(aes(y=..density..),      
                   binwidth=7000,
                   colour="black", fill="white") +
    geom_density(alpha=.2, fill="#FF6666")  

```

  Vemos que esta variable tiene un importe sesgo a la izquierda y parece que un cambio de variable de tipo logarítmico podría convertirla en una variable con distribución normal, cosa importante para el modelo lineal de regresión múltiple.  Confirmemos esta hipótesis realizando el cambio de variable en la misma y dibujando su función de distribución normal aproximada:

```{r}

  library(MASS)
  fitDistribution <- fitdistr(log10(train_test$SalePrice), densfun = "normal")
  ggplot(data = train_test) +
  geom_histogram(mapping = aes(x = log10(SalePrice), y = ..density..), col="white") +
  stat_function(fun = dnorm, 
      args = list(mean = fitDistribution$estimate[1], sd = fitDistribution$estimate[2], log = F), 
      color="red", lwd=1)

```

  Vemos que, efectivamente, lo que hemos comentado en el anterior apartado se cumple. 
  Detectamos también que el rango dinámico de la variable es muy grande en su parte    derecha sin que apenas haya valores en dicho intervalo, lo que invita a pensar en la presencia de "outliers". Dibujaremos sendos diagramas de cajas con la variable original y la variable transformada:

```{r}

library(ggpubr)

graf3 <- train_test %>% dplyr::select( SalePrice) %>%
  na.omit() %>%
  ggplot(aes(x=0,y=SalePrice)) +
    geom_boxplot(outlier.colour="black", outlier.shape=16,
             outlier.size=2, notch=FALSE)

graf4 <- train_test %>% dplyr::mutate(log10_saleprice = log10(SalePrice)) %>%
  dplyr::select(log10_saleprice) %>%
  na.omit() %>%
  ggplot(aes(x=0,y=log10_saleprice)) +
    geom_boxplot(outlier.colour="black", outlier.shape=16,
             outlier.size=2, notch=FALSE)

ggarrange(graf3,graf4)

```

   Vemos claramente la existencia de Outliers en esta variable que la transformación logarítmica no es capaz de resolver, tanto en los valores superiores como en los inferiores. En una parte futura de este apartado, detectaremos y almacenaremos en sendas variables estos Outliers para todas las variables independientes y tomar una decisión de cómo transformales en los apartados de tratamiento de variables cualitativas y cuantitativas.
   
   Ahora realizaremos un conjunto de gráficos cuantil/cuantil sobre las variables continuas y discretas para corroborar que hay pocas variables con una distribución normal:

```{r}
train_test %>% plot_qq(sampled_rows = 1000L)
```

  Las que más se aproximan a esta distribución son: LotArea, LotFrontage, GrLivArea, TotalBsmtSF y X1stFlrSF. Este diagrama pone en evidencia también la gran cantidad de Outliers que tienen algunas variables.
  
  Almacenaremos el grado de asimetría de dichas variables para en un futuro poder tener un criterio más claro de qué variables son candidatas a un tipo de transformación logarítmica:

```{r}
library(moments)
listasVariablesSkewness <-  na.omit(train_test %>% dplyr::select(var_continuas_discretas)) %>% skewness()
listasVariablesSkewness
variablesSkewnessAlto <- c('LotArea','LowQualFinSF','3SsnPorch','PoolArea','MiscVal')  
```

   Ahora procedermos a realizar el análisis vibariante de nuestros datos. Empezaremos con analizar los coeficientes de correlación entre las distintas variables. El siguiente diagrama intenta dibujar un mapa de calor de dichas correlaciones para las variables contínuas, pero debido a la gran cantidad de varibles en dicho diagrama no se puede visualizar nada con claridad:


```{r}
library(ggplot2)
splitDataset <- split_columns(train_test, binary_as_factor = FALSE)
plot_correlation(na.omit(splitDataset$continuous), type = "c" ,maxcat = 5L,theme_config = list(legend.position = "bottom", axis.text.x =element_text(angle = 90),axis.text.y = element_text(size = rel(0.4))  ))
```

  Crearemos una matriz de correlaciones con las variables continuas para intentar evidencia de mejor forma 

```{r}

library(corrr)
corrmatrix <-corrr::correlate(na.omit(train_test %>% dplyr::select(var_continuas)))
rplot(corrmatrix, legend = TRUE, shape = 16)
network_plot(corrmatrix)


```

```{r}
corrmatrix2 <-corrr::correlate(na.omit(train_test %>% dplyr::select(var_discretas)))
rplot(corrmatrix2, legend = TRUE, shape = 16)
network_plot(corrmatrix2)

corrmatrix3 <-corrr::correlate(na.omit(train_test %>% dplyr::select(var_continuas_discretas)))
rplot(corrmatrix3, legend = TRUE, shape = 16)
network_plot(corrmatrix3)
```


```{r}
library(caret)
correlacionesProblematicas <- findCorrelation(cor(na.omit(train_test %>% dplyr::select(var_continuas_discretas))),cutoff = 0.8, verbose = FALSE, names = TRUE)
correlacionesProblematicas
```





```{r}

 na.omit(train_test %>% dplyr::select(var_continuas)) %>% plot_scatterplot( by = "SalePrice", sampled_rows = 1000L) 

#geom_smooth(method=lm, se=FALSE, fullrange=TRUE)

```

```{r}

# na.omit(train_test %>% dplyr::select(var_discretas)) %>% plot_scatterplot( by = #"SalePrice", sampled_rows = 1000L) 

#geom_smooth(method=lm, se=FALSE, fullrange=TRUE)

```


 En cuanto a la detección de Outliers, como se ha indicado en 


```{r}
library(EnvStats)
listaOutliers <- list()
dataset_var_continuas <- train_test %>% dplyr::select(var_continuas)
iterator = 1 
for(i in colnames(dataset_var_continuas)) {
  outlier_values <- boxplot.stats(dataset_var_continuas[[i]])$out
  boxplot(dataset_var_continuas[[i]], main=i, boxwex=0.1)
  outliersRosen <- rosnerTest(dataset_var_continuas[[i]], k = length(outlier_values)-2, warn = F)
  listaOutliers[[iterator]] <- outliersRosen
   iterator<- iterator +1
}

for(i in listaOutliers) {
  print(c(i$data.name,i$n.outliers))
}

```

4. Detección, tratamiento e imputación de datos faltantes (1 punto)


A la hora de tratar con cualquier dataset hay que tener en cuenta que hay datos que pueden faltar. Es importante encontrarlos y tratarlos de manera correcta, pues podrían llevarnos a predecir de manera errónea y el modelo habría que tirarlo a la basura. El proceso de detección, tratamiento e imputación de datos faltantes se va a realizar de la siguiente manera:

    a. Análisis exploratorio inicial de los datos.
    
En el análisis exploratorio inicial de los datos, además de entender qué es lo que tenemos delante, hemos buscado datos que no concordaran con lo esperado: valores negativos en variables positivas, fechas imposibles o símbolos como "?", valores como "Unkown", etc. 

Esto nos llevó a darnos cuenta de que en algunas variable se acumulaban valores "NA" de manera extraña e investigando descubrimos que era un valor metido a propósito y que indicaban, por ejemplo,
    Alley: NA 	No alley access
    BsmtQual: NA	No Basement
    BsmtCond: NA	No Basement
    BsmtExposure: NA	No Basement
    BsmtFinType1: NA	No Basement
    BsmtFinType2:  NA	No Basement
    GarageType: NA	No Garage
    GarageFinish: NA	No Garage
    GarageQual: : NA	No Garage
    GarageCond: : NA	No Garage
    PoolQC:  NA	No Pool
    Fence:  NA	No Fence
    MiscFeature:   NA	None
    
Valores que, al no disponer la casa de jardín, piscina o garaje, por ejemplo, no se podía poner ningún valor. Así que lo hemos considerado como ausencia de jardín, piscina o garaje y no como NA's.
    
    b. Posibles causas de aparición de datos faltantes.
    
Tenemos que tener en cuenta si nuestros datos son de naturaleza 
    
- MCAR (Missing completely at Random): la probabilidad de que un dato falte es idéntica para todos los casos.
- MAR (Missing at Random): la probabilidad de que falte un valor depende de algún mecanimos conocido (pej, grupos en encuentas que son menos proclives a dar datos).
- MNAR (Missing not at Random): la probabilidad de que falte un valor depende de alguna variable no observada (pej, gente que miente).
    
Analizando nuestros datos vemos que nuestros datos faltantes pertenecen al grupo de MAR, ya que podemos tener capacidad o no para obtener cierta información de los domicilios de Boston, pero será totalmente aleatoria. Ésta es una buena noticia, ya que podemos utilizar técnicas de imputación para suplir los datos faltantes.
    
    c. Análisis exploratorio de datos faltantes.
    
Para hacer un análisis de los datos que nos faltan vamos a utilizar la biblioteca VIM. Ésta biblioteca nos será muy útil ya que nos ayuda a analizar las posibles relaciones y estructuras de los valores faltantes e imputados. 
    
```{r warning=FALSE,fig.width=40, fig.height=30}
    library(VIM)
    aggr_plot <- aggr(train_test,col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
```
    
Como hay muchas variables que no tienen valores faltantes, vamos a crear un dataset únicamente con las columnas que tienen missings para poder analizar mejor los datos. Para ello:
    
```{r warning=FALSE}
    na_counts <- sapply(train_test, function(x) sum(is.na(x)))
    na_counts_sort <- sort(na_counts, decreasing = TRUE)
    na_counts_sort <- na_counts_sort[1:20]
    (na_counts_sort)
    train_test_na <- train_test %>% select(LotFrontage, GarageYrBlt, MasVnrType, MasVnrArea, MSZoning, Functional, Exterior1st, Exterior2nd, Electrical, BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, KitchenQual, TotalBsmtSF, BsmtFullBath, BsmtHalfBath, GarageCars, GarageArea, SaleType)
    aggr_plot <- aggr(train_test_na,col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
```
    
Ahora podemos prestar verdadera atención a las columnas con datos faltantes. 
    
Si nos fijamos en la columna que más datos faltantes tiene, podemos ver en la descripción del dataset que son la cantidad de pies lineales que hay de acera hasta la puerta de la casa. Además, leyendo la documentación del dataset vemos que los NA's no significa que no tengan conexión con la acera (un edificio de varios pisos por ejemplo), sino que son datos faltantes. Hemos considerado que una columna con más de un 15% de datos faltantes nos va a desbalancear el dataset drásticamente, por lo que vamos a prescindir de este valor para nuestro estudio y para la imputación de missings, por lo que la borramos del dataset.
    
```{r message=FALSE, warning=FALSE, echo=FALSE}
train<-select(train, -LotFrontage)
test<-select(test, -LotFrontage)
train_test<-select(train_test, -LotFrontage)
train_test_na<-select(train_test_na, -LotFrontage)
full_dataset<-select(full_dataset, -LotFrontage)
```

```{r warning=FALSE}
    aggr_plot <- aggr(train_test_na,col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
    ```
    
Vemos en el último gráfico que, omitiendo la columna con datos faltantes mayor que el 5%, la cantidad de datos faltantes es menor que el 3%. Además vemos en la gráfica de la derecha que lo más habitual es que no falten todos los datos a la vez y a continuación que falten datos de la primera columna "GarageYtBtt". 
    
    
    d. Proporción datos faltantes. 
    
El siguiente paso es calcular la proporción de datos faltantes por columna. Para el caso en el que la proporción de datos faltantes sea menor que el 3% (0.03) imputaremos a los valores faltantes de variables cuantitativas su mediana o media, mientras que a las variables categóricas les imputaremos la categoría más frecuente. Para las columnas en que la proporcion de datos faltantes sea superior al 3% (0.03) tendremos que utilizar técnicas de imputación más avanzadas. Si en nuestro dataset se diera el caso en el que existen varias columnas de este útlimo tipo habría que realizar un análisis de sensibilidad para comprobar que no hemos alterado la naturaleza del dataset imputando los datos faltantes.


```{r}
colMeans(is.na(train_test_na))
```

Para el caso de las variables cuya proporción de missings es menor que el 3% (<=16 datos por columna) vamos a utilizar el método de imputar un valor de centralidad, en este caso la media. Antes de proceder a imputar, vemos que 

- Categóricas: MasVnrType, MSZoning, Functional, Electrical, KitchenQual, SaleType, Exterior1st, Exterior2nd, BsmtFullBath, BsmtHalfBath, Utilities.

- Cuantitativas: GarageYrBlt, MasVnrArea, GarageCars, GarageArea, BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF.

Para imputar de manera eficaz y sin tener que analizar por separado las variables categóricas de las cuantitativas vamos a utilizar la biblioteca HMISC. Esta biblioteca tiene dos funciones altamente potentes: impute() y aregImpute(). Se diferencian entre sí en que en la segunda puedes utilizar regresiones, bootstrapping y otros métodos para imputar valores.

```{r}
summary_antes_imputar <- summary(train_test)
#para las variables cuantitativas con una proporción del faltantes menor que el 3%,
#imputaremos el valor de la media
cuantitativas <- c('MasVnrArea','GarageCars','GarageArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF','BsmtFullBath', 'BsmtHalfBath')
for (i in cuantitativas){
  list_values <- ifelse(is.na(train_test[[i]]), 
                       round(mean(train_test[[i]], na.rm=TRUE), 0), train_test[[i]])
  train_test[[i]] <- list_values
  }

train_test
#para variables categoricas con una proporción de datos faltantes menor que el 3%
#vamos a imputar el valor más frecuente.  


categoricas <- c('MasVnrType', 'MSZoning', 'Functional', 'Electrical',
'KitchenQual', 'SaleType', 'Exterior1st', 'Exterior2nd',  'Utilities')
for (i in cuantitativas){
  y = as.data.frame(table(unlist(train_test[[i]])))
  sorted_list <-y[with(y, order(-Freq)),]
  frecuent_value <- sorted_list$Var1[1]
  list_values <- c()
  for(j in 1:length(train_test[[i]])) {
    if(is.na(train_test[[i]][j])) {
      train_test[[i]][j] = frecuent_value
      na.rm=TRUE
      list_values = c(list_values, train_test[[i]][j])
    }
    else {
      list_values = c(list_values, train_test[[i]][j])
    }
  }
  train_test[[i]] <- list_values
}

summary_despues_imputar <- summary(train_test)
```

Solo nos faltaría una variable por imputar sus valores: GarageYrBlt. Esta columna indica el año en el que se construyó el garaje de la propiedad. No lo vamos a imputar con el valor medio ya que la proporción de datos faltantes es mayor al 3%, así que lo que proponemos para su imputación es lo siguiente: ya que conocemos el vecindario al que pertenecen los pisos, es lógico que el año de construcción del garaje sea similar para todo el vecindario. Vamos a proceder a agrupar los garages por vecindario e imputaremos el año medio correspondiente.

```{r}
library(tidyverse)
vecindario_precioGaraje<- train_test %>% select(Neighborhood, GarageYrBlt)

library(dplyr)
vecindario_agrupado <- vecindario_precioGaraje %>% 
    group_by(Neighborhood) %>% 
    summarise(mean_data = round(mean(GarageYrBlt,na.rm=TRUE),0))
summary(vecindario_agrupado)

#En la variable grouped_list tenemos los vecindarios de Boston y la media del año
#en el que fueron construidos sus garajes. Esos son los valores que usaremos para imputar.

year_corregido<- c()
for(j in 1:length(vecindario_precioGaraje$GarageYrBlt)) {
  if(is.na(vecindario_precioGaraje$GarageYrBlt[j])) {
    #obtenemos el vecindario correspondiente al NA
    vecindario = vecindario_precioGaraje$Neighborhood[j]
    #ahora que conocemos el vecindario, tenemos que saber cual es el año que le corresponde
        #Dentro de la lista de vecindarios, sacamos su numero de fila
    index_vecindario = which(grepl(vecindario, vecindario_agrupado$Neighborhood))
    
    #Entramos en este if porque hay dos vecindarios: Sawyer y SawyerW. Cuando buscamos el 
    #de Sawyer nos da el indice de los dos vecindarios, asi que nos quedamos con el primero.
    if (length(index_vecindario)>1){
      index_vecindario = index_vecindario[1]
    }
    year_a_imputar = vecindario_agrupado[index_vecindario,2]
    
    na.rm=TRUE
    year_corregido<-c(year_corregido,year_a_imputar)
  }
  else {
    year_corregido<-c(year_corregido,vecindario_precioGaraje$GarageYrBlt[j])
    next 
  }
}

year_corregido<- unlist(year_corregido)
length(year_corregido)

#actualizamos la columna en el dataset
train_test["GarageYrBlt"]<-year_corregido
train_test$GarageYrBlt

library(dplyr)
vecindario_agrupado2 <- vecindario_precioGaraje %>% 
    group_by(Neighborhood) %>% 
    summarise(mean_data = round(mean(GarageYrBlt,na.rm=TRUE),0))
summary(vecindario_agrupado2)

```


Y ya tendríamos todas las columnas con missing imputadas. Hay que destacar que hemos imputado los valores faltantes en todo el dataset (menos validación, como es obvio), más adelante separaremos en train y test.


5. Transformaciones de variables cuantitativas (1 punto)

```{r}

firsrtFlrSF <- '1stFlrSF'
secondFlrSF   <- '2ndFlrSF'
thirdSsnPorch <- '3SsnPorch'

train <- train %>% dplyr::mutate( TotalSF = TotalBsmtSF + !!as.symbol(firsrtFlrSF) + !!as.symbol(secondFlrSF)  )
 train <- train %>% dplyr::mutate( Total_Bathrooms = FullBath + 0.5*HalfBath +  BsmtFullBath + 0.5*BsmtHalfBath )
 train <- train %>% dplyr::mutate( Total_porch_SF = OpenPorchSF +!!as.symbol(thirdSsnPorch) +  EnclosedPorch + ScreenPorch + WoodDeckSF )
 train <- train %>% dplyr::mutate( TotalSqrFootage = BsmtFinSF1 + BsmtFinSF2 + !!as.symbol(firsrtFlrSF) + !!as.symbol(secondFlrSF)  )
 
test <- test %>% dplyr::mutate( TotalSF = TotalBsmtSF + !!as.symbol(firsrtFlrSF) + !!as.symbol(secondFlrSF)  )
 test <- test %>% dplyr::mutate( Total_Bathrooms = FullBath + 0.5*HalfBath +  BsmtFullBath + 0.5*BsmtHalfBath )
 test <- test %>% dplyr::mutate( Total_porch_SF = OpenPorchSF +!!as.symbol(thirdSsnPorch) +  EnclosedPorch + ScreenPorch + WoodDeckSF ) 
 test <- test %>% dplyr::mutate( TotalSqrFootage = BsmtFinSF1 + BsmtFinSF2 + !!as.symbol(firsrtFlrSF) + !!as.symbol(secondFlrSF)  )
 
# esta variable tiene los pies cuadrados "oficiales" del interior de la casa
train_test <- train_test %>% dplyr::mutate( TotalSF = TotalBsmtSF + !!as.symbol(firsrtFlrSF) + !!as.symbol(secondFlrSF)  )
# esta variable tiene los pies cuadrados de los cuartos de baño de la casa
 train_test <- train_test %>% dplyr::mutate( Total_Bathrooms = FullBath + 0.5*HalfBath +  BsmtFullBath + 0.5*BsmtHalfBath )
 # esta variable tiene los pies cuadrados del porche
 train_test <- train_test %>% dplyr::mutate( Total_porch_SF = OpenPorchSF +!!as.symbol(thirdSsnPorch) +  EnclosedPorch + ScreenPorch + WoodDeckSF ) 
 # esta variable tiene los pies cuadrados finalizados de la casa (tiene en cuenta las variables de sotano acabado y no tiene en cuenta la variable TotalBsmtSF)
 train_test <- train_test %>% dplyr::mutate( TotalSqrFootage = BsmtFinSF1 + BsmtFinSF2 + !!as.symbol(firsrtFlrSF) + !!as.symbol(secondFlrSF)  ) 
 
 
 
 
```



6. Procesado de variables cualitativas (1 punto)

```{r}

#MSSubClass: 
leveslMSubClass <- c(
"1-STORY 1946 & NEWER ALL STYLES",
"1-STORY 1945 & OLDER",
"1-STORY W/FINISHED ATTIC ALL AGES",
"1-1/2 STORY - UNFINISHED ALL AGES",
"50	1-1/2 STORY FINISHED ALL AGES",
"60	2-STORY 1946 & NEWER",
"2-STORY 1945 & OLDER",
"2-1/2 STORY ALL AGES",
"SPLIT OR MULTI-LEVEL",
"85	SPLIT FOYER",
"DUPLEX - ALL STYLES AND AGES",
"1-STORY PUD (Planned Unit Development) - 1946 & NEWER",
"1-1/2 STORY PUD - ALL AGES",
"160	2-STORY PUD - 1946 & NEWER",
"PUD - MULTILEVEL - INCL SPLIT LEV/FOYER",
"2 FAMILY CONVERSION - ALL STYLES AND AGES"
)

#OverallQual, OverallCond (dejarlas como estan)
levesl1_10 <- c("Very Poor","Poor","Fair","Below Average","Average","Above Average","Good","Very Good","Excellent","Very Excellent")

#ExterQual , ExterCond , HeatingQC, KitchenQual,GarageQual,GarageCond
return_position1_5 <- function(elements) {
    levesl1_5 <- c('Po','Fa','TA','Gd','Ex')
    pos <- match(elements,levesl1_5)
    elem <- which(levesl1_5 %in% elements)
    return(levesl1_5[elem])
}


#BsmtQual,BsmtCond,FireplaceQu
return_position1_6 <- function(elements) {
    levesl1_6 <- c('NA','Po','Fa','TA','Gd','Ex')
    pos <- match(elements,levesl1_6)
    elem <- which(levesl1_6 %in% elements)
    return(levesl1_6[elem])
}


#BsmtExposure
return_position1_5_B <- function(elements) {
    levesl1_5_B <- c('NA','No','Mn','Av','Gd')
    pos <- match(elements,levesl1_5_B)
    elem <- which(levesl1_5_B %in% elements)
    return(levesl1_5_B[elem])
}


#BsmtFinType1 , BsmtFinType2
return_position1_7 <- function(elements) {
    levesl1_7 <- c('NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ')
    pos <- match(elements,levesl1_7)
    elem <- which(levesl1_7 %in% elements)
    return(levesl1_7[elem])
}

#CentralAir
levesl_2 <- c('N','Y')  

#GarageFinish
return_levels_garage <- function(elements) {
    levels_garage <-c('NA','Unf','RFn','Fin')
    pos <- match(elements,levels_garage)
    elem <- which(levels_garage %in% elements)
    return(levels_garage[elem])
}


# PoolQC
return_levesl_poolQC <- function(elements) {
    levesl_poolQC <- c('NA','Fa','TA','Gd','Ex')
    pos <- match(elements,levesl_poolQC)
    elem <- which(levesl_poolQC %in% elements)
    return(levesl_poolQC[elem])
}


library(forcats)

      #OverallCond
      train <- train %>% dplyr::mutate( ExterQual:=fct_relevel(ExterQual,return_position1_5))
      test <- test %>% dplyr::mutate( ExterQual:=fct_relevel(ExterQual,return_position1_5))
      #ExterCond , 
      train <- train %>% dplyr::mutate( ExterCond := fct_relevel(ExterCond,return_position1_5))
      test <- test %>% dplyr::mutate( ExterCond := fct_relevel(ExterCond,return_position1_5))
      #HeatingQC, 
      train <- train %>% dplyr::mutate( HeatingQC := fct_relevel(HeatingQC,return_position1_5))
      test <-  test %>% dplyr::mutate( HeatingQC := fct_relevel(HeatingQC,return_position1_5))
      #KitchenQual,
      train <- train %>% dplyr::mutate( KitchenQual := fct_relevel(KitchenQual,return_position1_5))
      test <-  test %>% dplyr::mutate( KitchenQual := fct_relevel(KitchenQual,return_position1_5))
      #GarageQual,
      train <- train %>% dplyr::mutate( GarageQual := fct_relevel(GarageQual,return_position1_5))
      test <-  test %>% dplyr::mutate( GarageQual := fct_relevel(GarageQual,return_position1_5))
      #GarageCond
      train <- train %>% dplyr::mutate( GarageCond := fct_relevel(GarageCond,return_position1_5))
      test <-  test %>% dplyr::mutate( GarageCond := fct_relevel(GarageCond,return_position1_5))
      #BsmtQual
      train <- train %>% dplyr::mutate( BsmtQual := fct_relevel(BsmtQual,return_position1_6))
      test <-  test %>% dplyr::mutate( BsmtQual := fct_relevel(BsmtQual,return_position1_6))
      #BsmtCond,
      train <- train %>% dplyr::mutate( BsmtCond := fct_relevel(BsmtCond,return_position1_6))
      test <- test %>% dplyr::mutate( BsmtCond := fct_relevel(BsmtCond,return_position1_6))
      #FireplaceQu
      train <- train %>% dplyr::mutate(FireplaceQu := fct_relevel(FireplaceQu,return_position1_6))
      test <-  test %>% dplyr::mutate(FireplaceQu := fct_relevel(FireplaceQu,return_position1_6))
      #BsmtExposure
      train <- train %>% dplyr::mutate( BsmtExposure := fct_relevel(BsmtExposure,return_position1_5_B))
      test <-  test %>% dplyr::mutate( BsmtExposure := fct_relevel(BsmtExposure,return_position1_5_B))
      #BsmtFinType1 
      train <- train %>% dplyr::mutate( BsmtFinType1 := fct_relevel(BsmtFinType1,return_position1_7))
      test <-  test %>% dplyr::mutate( BsmtFinType1 := fct_relevel(BsmtFinType1,return_position1_7))
      #BsmtFinType2
      train <- train %>% dplyr::mutate( BsmtFinType1 := fct_relevel(BsmtFinType2,return_position1_7))
      test <-  test %>% dplyr::mutate( BsmtFinType1 := fct_relevel(BsmtFinType2,return_position1_7))
     #GarageFinish
      train <- train %>% dplyr::mutate( GarageFinish := fct_relevel(GarageFinish,return_levels_garage))
      test <-  test %>% dplyr::mutate( GarageFinish := fct_relevel(GarageFinish,return_levels_garage))
      # PoolQC
      train <- train %>% dplyr::mutate( PoolQC := fct_relevel(PoolQC,return_levesl_poolQC))
      test <-  test %>% dplyr::mutate( PoolQC := fct_relevel(PoolQC,return_levesl_poolQC))

# YearBuilt: discretizamos la variable en tramos
# YearRemodAdd: discretizamos la variable en tramos
train$YearBuilt <- cut(train$YearBuilt, 
                   breaks=c(-Inf, 1930, 1960, 1990,Inf), 
                   labels=c("1900-1930","1930-1960","1960-1990","1990-"))   
test$YearBuilt <- cut(test$YearBuilt, 
                   breaks=c(-Inf, 1930, 1960, 1990,Inf), 
                   labels=c("1900-1930","1930-1960","1960-1990","1990-"))   

      
train$YearRemodAdd <- cut(train$YearRemodAdd, 
                   breaks=c(-Inf, 1930, 1960, 1990,Inf), 
                   labels=c("1900-1930","1930-1960","1960-1990","1990-"))   
test$YearRemodAdd <- cut(test$YearRemodAdd, 
                   breaks=c(-Inf, 1930, 1960, 1990,Inf), 
                   labels=c("1900-1930","1930-1960","1960-1990","1990-"))   

    
# creamos nuevas variablea que indiquen si la casa tiene piscina, segunda planta, etc
#PoolArea,2ndFlrSF,GarageArea,TotalBsmtSF,Fireplaces
      
test <-  test %>% dplyr::mutate( hasPool := ifelse(PoolArea > 0, "True", "False")) 
train <-  train %>% dplyr::mutate( hasPool := ifelse(PoolArea > 0, "True", "False"))       
 
test <-  test %>% dplyr::mutate( hasGarage := ifelse(GarageArea > 0, "True", "False")) 
train <-  train %>% dplyr::mutate( hasGarage := ifelse(GarageArea > 0, "True", "False"))  
 
test <-  test %>% dplyr::mutate( hasBasement := ifelse(TotalBsmtSF > 0, "True", "False")) 
train <-  train %>% dplyr::mutate( hasBasement := ifelse(TotalBsmtSF > 0, "True", "False")) 
 
test <-  test %>% dplyr::mutate( hasFirePlaces := ifelse(Fireplaces > 0, "True", "False")) 
train <-  train %>% dplyr::mutate( hasFirePlaces := ifelse(Fireplaces > 0, "True", "False")) 

 
test <-  test %>% dplyr::mutate( has2ndFloor := ifelse(!!as.symbol(secondFlrSF)  > 0, "True", "False")) 
train <-  train %>% dplyr::mutate( has2ndFloor := ifelse(!!as.symbol(secondFlrSF)  > 0, "True", "False")) 
    

# para dummify variables si es necesario tenemos esta funcion del paquete dataexplorer
#train <- dummify(train, maxcat = 50L, select = var_nominales)
   
```

7. Selección de variables (1 punto)
8. Ajuste, interpretación y diagnosis del modelo de regresión lineal múltiple (2 puntos)
9. Valoración del profesor (1 punto)
