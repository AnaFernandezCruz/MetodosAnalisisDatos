---
title: "Métodos de Análisis de Datos"
author: "Ana Fernández Cruz, Jesús Gallego Olivas y Miguel Ángel Sánchez Alcázar."
output: html_document
---

A continuación, se detallan los diferentes apartados evaluables en el desarrollo de la práctica y su puntuación. La puntuación completa corresponde al correcto uso, y justificación, de cada una de las técnicas empleadas.

1. Uso de herramienta/s de control de versiones (1 punto)

Para el control de versiones utilizaremos github. El repositorio se encuentra en https://github.com/AnaFernandezCruz/MetodosAnalisisDatos

2. Definición de objetivos (1 punto)

La presente práctica intentará crear un modelo de regresión lineal múltiple para un dataset con las siguientes características. La variable que se intentará inferir será la esperanza de vida


3. Análisis exploratorio inicial (1 punto)

Antes de empezar a realizar la práctica tenemos que cargar los dataset incluidos en la página de Kaggle, unificarlos en un solo dataset y dividirlo en train/test/validación. Para ello:

```{r message=FALSE, warning=FALSE}


library(readr)
library(plyr)

pathDatos = './Dataset/'
pathLocal = './'
fileTrain = paste(pathDatos,"train.csv",sep="", collapse = NULL)
fileTest = paste(pathDatos,"test.csv",sep="", collapse = NULL)
fileDatosPK = paste(pathDatos,"sample_submission.csv",sep="", collapse = NULL)
fileDatosTrainTest = paste(pathLocal,"train_test.csv",sep="", collapse = NULL)
fileDatosValidacion = paste(pathLocal,"validacion.csv",sep="", collapse = NULL)

borra_columnas_muchos_faltantes = TRUE
borra_columnas_incomodas = FALSE
columnas_borrar_faltantes <- c('FireplaceQu','Fence','Alley','MiscFeature','PoolQC','GarageType','GarageCond','GarageQual','GarageFinish','GarageYrBit','LoftFrontage')
columnas_borrar_incomodas <- c('BsmtFinType1','LowQualFinSF','MasVnrArea','BsmtHalfBath','EnclosedPorch','KitchenAbvGr','MiscVal','PoolArea','ScreenPorch','Utilities','Condition2','RoofMalt','Heating','Street')


if(!file.exists(fileDatosTrainTest)) {

 

  
  
    train_kaggle <- read_csv(fileTrain)
    head(train_kaggle)
    
    test_kaggle <- read_csv(fileTest)
    head(test_kaggle)
    
    claves_primarias <- read_csv(fileDatosPK)
    head(claves_primarias)
    
    #Mergeamos el archivo de train y test ya que tienen las mismas columnas.
    
    test_kaggle <- join(test_kaggle, claves_primarias, by = c("Id", "Id"), type = "inner")
    full_dataset <- union(train_kaggle, test_kaggle)
    head(full_dataset)
    
    dt = sort(sample(nrow(full_dataset), nrow(full_dataset)*.1))

    if(borra_columnas_muchos_faltantes) {
    
      #full_dataset = subset( full_dataset, select = -columnas_borrar_faltantes)
      full_dataset <- full_dataset %>% select(-one_of(columnas_borrar_faltantes))
    
    }
  
    if(borra_columnas_incomodas) {
    
      #full_dataset = subset( full_dataset, select = -columnas_borrar_faltantes)
      full_dataset <- full_dataset %>% select(-one_of(columnas_borrar_incomodas))
    
    }
    
    validacion<-full_dataset[dt,]
    write.csv(validacion, fileDatosValidacion,row.names=F)
    
    train_test<-full_dataset[-dt,]
    write.csv(train_test, fileDatosTrainTest,row.names=F)
  
}

train_test <- read_csv(fileDatosTrainTest)
set.seed(55)
dt = sort(sample(nrow(train_test), nrow(train_test)*.7))
train<-train_test[dt,]
test<-train_test[-dt,]

```

Una vez tenemos los 3 csv unidos en uno, procedemos a separar los datos de validación.

```{r}
library(DataExplorer)
introduce(test)
```

```{r}
plot_intro(test)
```

```{r}
library(skimr)
library(pander)
skim(test)  %>% pander()
```

```{r}
library(VIM)
aggr(test)
```


```{r}
missing_data <- plot_missing(test)
```


```{r}
# DataExplorer::create_report(datosOriginales) 
plot_bar(test)
```


```{r}
test %>% plot_histogram()
```

```{r}
test %>% plot_qq(sampled_rows = 1000L)
```


```{r}
plot_correlation(na.omit(test), maxcat = 5L)
```


```{r}
var_discretas <- c('BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd',
                'Fireplaces','GarageCars','GarageYrBlt','YearBuilt','YearRemodAdd','YrSold','MoSold')

var_continuas <- c('LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch', '3SsnPorch','ScreenPorch','PoolArea','MiscVal','SalePrice')

var_ordinales <- c('LotShape','Utilities','LandSlope','OverallQual','OverallCond','ExterQual','ExterCond',
               'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC','CentralAir',
               'Electrical','KitchenQual','Functional','FireplaceQu','GarageFinish','GarageQual','GarageCond',
               'PavedDrive','PoolQC','Fence')

var_nominales <- c('MSSubClass','MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood',
               'Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st',
               'Exterior2nd','MasVnrType','Foundation','Heating','GarageType','MiscFeature',
               'SaleType','SaleCondition')




```


4. Detección, tratamiento e imputación de datos faltantes (1 punto)
5. Transformaciones de variables cuantitativas (1 punto)
6. Procesado de variables cualitativas (1 punto)
7. Selección de variables (1 punto)
8. Ajuste, interpretación y diagnosis del modelo de regresión lineal múltiple (2 puntos)
9. Valoración del profesor (1 punto)

